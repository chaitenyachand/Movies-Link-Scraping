{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import IMDb\n",
    "from imdb._exceptions import IMDbDataAccessError\n",
    "import csv\n",
    "import time\n",
    "import threading\n",
    "import os\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia = IMDb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_details(movie, id):\n",
    "        #print(movie.keys())\n",
    "        if 'title' in movie.keys():\n",
    "            movie_name = movie.get('title', 'N/A')\n",
    "            cover_photo = movie.get('cover url', 'N/A')\n",
    "            source_link = f\"https://www.imdb.com/title/tt{id:07d}/\"\n",
    "            rating = movie.get('rating', 'N/A')\n",
    "            trailer_link = f\"https://www.imdb.com/title/tt{id:07d}/videogallery\"\n",
    "            categories = ', '.join(movie.get('genres', []))\n",
    "            return [id, movie_name, cover_photo, source_link, rating, trailer_link, categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(movie_details, http_error, file_name):\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Id', 'Movie Name', 'Cover Photo', 'Source Link', 'Rating', 'Trailer Link', 'Categories'])\n",
    "        for details in movie_details:\n",
    "            writer.writerow(details)\n",
    "    \n",
    "    with open('http_error.csv', 'a+') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for id in http_error:\n",
    "            writer.writerow(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_movie_details(start_id, end_id):\n",
    "    movies = []\n",
    "    http_error = []\n",
    "    for id in range (start_id, end_id+1):     #making end_id inclusive\n",
    "        try:\n",
    "            movie = ia.get_movie(id)\n",
    "            movies.append(fetch_details(movie, id))\n",
    "            print(f\"ID:-{id}\")\n",
    "        except IMDbDataAccessError as e:\n",
    "            print(e)\n",
    "            movies.append([id, '', '', '', '', '', ''])\n",
    "            http_error.append([id,])\n",
    "            print(f\"Error with ID:-{id}\")\n",
    "        except HTTPError as e:\n",
    "            http_error.append([id,])\n",
    "            print('HTTPError Captured!')\n",
    "\n",
    "    print(f\"From:- {start_id}, {end_id} len is:-{len(movies)}\")\n",
    "    write_data(movies, http_error, f'imdb_data({start_id}-{end_id}).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_parallel(start_id, end_id, batch_size):\n",
    "\n",
    "    threads = []\n",
    "\n",
    "    # batch_size = 100\n",
    "    # start_id = 24555\n",
    "    # end_id = 25555 \n",
    "    \n",
    "    current_id = start_id\n",
    "\n",
    "    while current_id <= end_id:\n",
    "        batch_end_id = min(current_id + batch_size - 1, end_id)\n",
    "        print(f\"Processing batch: {current_id} to {batch_end_id}\")\n",
    "        thread = threading.Thread(target=fetch_movie_details, args=(current_id, batch_end_id))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        #print(f\"Doing Batch:-{start_id}, {end_id}\")\n",
    "\n",
    "        current_id += batch_size\n",
    "        #print(f\"after Doing Batch:-{start_id}, {end_id}\")\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "start_id = 45556       #done\n",
    "end_id = 54109          #done\n",
    "\n",
    "# for i in range(0, 2):\n",
    "    \n",
    "#     if i == 0:\n",
    "#         start_id = 34556        #not done\n",
    "#         end_id = 44555          #not done\n",
    "#         print(f\"Starting for Batch{start_id} to {end_id}\")\n",
    "#     elif i == 1:\n",
    "#         start_id = 44556        #not done\n",
    "#         end_id = 54109          #not done\n",
    "#         print(f\"Starting for Batch{start_id} to {end_id}\")\n",
    "\n",
    "fetch_parallel(start_id, end_id, batch_size)        #making end_id Inclusive\n",
    "\n",
    "#time.sleep(600)\n",
    "#print(\"Cooldown Period of 300 Seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght:-59112\n",
      "Sucessfully Created and Saved file!\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir()\n",
    "output_file = 'MergeIMDb data(24555-54109).csv'\n",
    "\n",
    "def merge_csv(file_list, output_file):\n",
    "\n",
    "    mergedData = []\n",
    "\n",
    "    for file in file_list:\n",
    "        if file.endswith('.csv'):\n",
    "            with open(file, 'r') as file:\n",
    "                data = csv.reader(file)\n",
    "                for row in data:\n",
    "                    if 'Id' not in row:\n",
    "                        #print(i)\n",
    "                        mergedData.append(row)\n",
    "    \n",
    "    print(f\"Lenght:-{len(mergedData)}\")\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Id', 'Movie Name', 'Cover Photo', 'Source Link', 'Rating', 'Trailer Link', 'Categories'])\n",
    "        writer.writerows(mergedData)\n",
    "        print(\"Sucessfully Created and Saved file!\")\n",
    "           \n",
    "merge_csv(file_list, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
